# Evaluation Results

## Accuracy

| Model | xbrl_tags | xbrl_value |
|------| --- | --- |
| meta-llama/Llama-3.1-8B-Instruct-8bits-r8 | 0.9727 | 0.9902 |


## F1 Score

| Model | xbrl_tags | xbrl_value |
|------| --- | --- |
| meta-llama/Llama-3.1-8B-Instruct-8bits-r8| 0.0000 | 0.0000 |
